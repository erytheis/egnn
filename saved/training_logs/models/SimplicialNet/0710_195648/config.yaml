arch:
  args:
    edge:
      act: Tanh
      alpha: 0.1
      conv_kwargs:
        bias: false
        lin_act: Tanh
        type: SimplicialLayer
      embedding_bias: true
      embedding_channels: 10
      embedding_layers: 2
      hidden_channels: 20
      in_channels: 3
      out_channels: 1
    num_layers: 38
  type: SimplicialCN
dataset:
  args:
    cache_transformed: true
    reload_data: false
    skip_features:
    - flowrate_scaled
  pre_transforms:
  - args:
      log: true
      log_base: 10
      remove_original: true
    type: HazenWilliamsWeights
  subsets:
  - args:
      root: saved/simulations/wntr/mod/experiment_3.2A
    type: WDSGNNDataset
  transforms:
  - args:
      extend_dimensions: true
      fully_connected: false
    type: VirtualSink
  - args:
      columns:
      - flowrate
    type: RandomFlipEdges
  - args:
      normalized: true
    type: ToSimplexData
  - args:
      attribute_key: edge_attr
      mask_value: 0
      reference_key: virtual
      reference_value: 0
      target_key: flowrate
    type: Mask
debug: false
device: cuda:0
inspect: false
loader:
  args:
    batch_size: 10
    num_workers: 0
    shuffle: false
    test_split: 0.1
    validation_split: 0.1
  type: BaseGNNDataLoader
loss:
- args:
    virtual_idx: -1
    weight: 100
  type: EdgeMSELoss
metrics:
- mae
- r2
n_gpu: 1
name: SimplicialNet
optimizer:
  args:
    lr: 0.003
  reset: true
  type: Adam
resume: null
seed: 90342
trainer:
  args:
    cache_clear_period: 50
    early_stop: 5000
    epochs: 140000
    monitor: min val/loss
    plot_period: 500
    save: true
    save_dir: saved/training_logs
    save_period: 500
    tensorboard: true
    validation_period: 50
    verbosity: 2
    y_dim:
    - 1
    - 0
  type: WDSSimplexTrainer
